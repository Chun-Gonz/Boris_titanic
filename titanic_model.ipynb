{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443b22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71b4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('F:\\\\Titanic\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae8c044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the training dataset: \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print('First few rows of the training dataset: ')\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4525b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics of the training dataset:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary statistics of the training dataset:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a34896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information about the training dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInformation about the training dataset:\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036b208d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8254807",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f42018",
   "metadata": {},
   "source": [
    "#### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3234eb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Impute missing ages with the mean age\n",
    "mean_age = train_df['Age'].mean()\n",
    "train_df['Age'].fillna(mean_age, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5346d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop the 'Cabin' column\n",
    "train_df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2edb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Impute missing 'Embarked' values with the most common port\n",
    "most_common_embarked = train_df['Embarked'].mode()[0]\n",
    "train_df['Embarked'].fillna(most_common_embarked, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d051e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values after preprocessing:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any remaining missing values\n",
    "print(\"Number of missing values after preprocessing:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b895094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert categorical variables using one-hot encoding\n",
    "train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e04bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature Engineering (Example: FamilySize)\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3baae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe after converting categorical variables and feature engineering:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare  Sex_male  Embarked_Q  Embarked_S  FamilySize  \n",
      "0         A/5 21171   7.2500         1           0           1           2  \n",
      "1          PC 17599  71.2833         0           0           0           2  \n",
      "2  STON/O2. 3101282   7.9250         0           0           1           1  \n",
      "3            113803  53.1000         0           0           1           2  \n",
      "4            373450   8.0500         1           0           1           1  \n"
     ]
    }
   ],
   "source": [
    "# Check the updated dataframe\n",
    "print(\"Updated dataframe after converting categorical variables and feature engineering:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00c8a87",
   "metadata": {},
   "source": [
    "# Model Selection and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bb32f",
   "metadata": {},
   "source": [
    "### Logistic regression model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da134e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model: 0.7988826815642458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Splitting the dataset into features and target variable\n",
    "X = train_df.drop(['PassengerId', 'Survived', 'Name', 'Ticket'], axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy of Logistic Regression model:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0fbae",
   "metadata": {},
   "source": [
    "### Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5af5591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree model: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dt = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Accuracy of Decision Tree model:\", accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8adc9d",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c975a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest model: 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy of Random Forest model:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a79e36",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d52fca8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine (SVM) model: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy of Support Vector Machine (SVM) model:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d93fc",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8668e724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gradient Boosting model: 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize and train the Gradient Boosting model\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
    "gradient_boosting_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_gb = gradient_boosting_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Accuracy of Gradient Boosting model:\", accuracy_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce25d01",
   "metadata": {},
   "source": [
    "# Improving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c4aba",
   "metadata": {},
   "source": [
    "### Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa885c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest model with new features: 0.8324022346368715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Read the original training and test data\n",
    "train_df = pd.read_csv(\"F:\\\\Titanic\\\\train.csv\")\n",
    "\n",
    "# Feature engineering\n",
    "# Title from Name\n",
    "train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "train_df['Title'] = train_df['Title'].replace(['Lady', 'Countess', 'Dona'], 'Royalty')\n",
    "train_df['Title'] = train_df['Title'].replace(['Mme'], 'Mrs')\n",
    "train_df['Title'] = train_df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "train_df['Title'] = train_df['Title'].replace(['Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer'], 'Special')\n",
    "\n",
    "# Family Size\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "\n",
    "# Is Alone\n",
    "train_df['IsAlone'] = 0\n",
    "train_df.loc[train_df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Age Group\n",
    "train_df['AgeGroup'] = pd.cut(train_df['Age'], bins=[0, 12, 18, 60, 200], labels=['Child', 'Teenager', 'Adult', 'Elderly'])\n",
    "\n",
    "# Fare per Person\n",
    "train_df['FarePerPerson'] = train_df['Fare'] / train_df['FamilySize']\n",
    "\n",
    "# Cabin Deck\n",
    "train_df['Deck'] = train_df['Cabin'].str[:1]\n",
    "train_df['Deck'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked', 'Title', 'AgeGroup', 'Deck'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(train_df)\n",
    "train_df_imputed = pd.DataFrame(imputer.transform(train_df), columns=train_df.columns)\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = train_df_imputed.drop('Survived', axis=1)\n",
    "y = train_df_imputed['Survived']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model with the new features\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Accuracy of Random Forest model with new features:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc32247",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d963928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8c3b298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.87      0.86       105\n",
      "         1.0       0.81      0.78      0.79        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.83      0.83       179\n",
      "weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31312061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[91 14]\n",
      " [16 58]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
